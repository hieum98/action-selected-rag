from typing import List, Union
from agents.llm_agents import LLMAgent
from prompts import (
    evaluate,
    generate_direct_answer,
    generate_one_next_step,
    generate_subquestion_and_answer,
    reanswer_subquestion,
    rephase_question,
)


class Generator:
    def __init__(
            self, 
            online_model_kwargs=None, 
            offline_model_kwargs=None,
            generate_kwargs={}
            ):
        assert online_model_kwargs is not None or offline_model_kwargs is not None, "At least one model configuration must be provided."
        if online_model_kwargs is not None:
            assert all(key in online_model_kwargs for key in ['model_name', 'url']), "Online model configuration must include 'model_name' and 'url'."
            online_model_kwargs.update(generate_kwargs)
        if offline_model_kwargs is not None:
            assert all(key in offline_model_kwargs for key in ['model_name', 'agent_type']), "Offline model configuration must include 'model_name' and 'agent_type'."
            offline_model_kwargs.update(generate_kwargs)
                
        self.llm_agent = LLMAgent(
            online_model_kwargs=online_model_kwargs,
            offline_model_kwargs=offline_model_kwargs
        )

        # Initialize prompts
        self.evaluate_answer_prompt = evaluate.EVALUATE_ANSWER_PROMPT
        self.eval_examples = None  # Placeholder for direct answer examples
        
        self.generate_direct_answer_prompt = generate_direct_answer.DIRECT_ANSWER_PROMPT
        self.direct_answer_examples = None

        self.generate_one_next_step_prompt = generate_one_next_step.ONE_NEXT_STEP_PROMPT
        self.one_next_step_examples = None

        self.generate_subquestion_and_answer_prompt = generate_subquestion_and_answer.SUBQUESTION_AND_ANSWER_PROMPT
        self.subquestion_and_answer_examples = None
        
        self.reanswer_subquestion_prompt = reanswer_subquestion.REANSWER_PROMPT
        self.reanswer_subquestion_examples = None

        self.rephase_question_prompt = rephase_question.REPHRASE_QUESTION_PROMPT
        self.rephase_question_examples = None

    def evaluate_answer(self, question: str, correct_answer: Union[str, List[str]], predicted_answer: str):
        """
        Evaluates the quality of a predicted answer against a correct answer.
        
        Args:
            question (str): The question being answered.
            correct_answer (str): The correct answer to the question.
            predicted_answer (str): The answer generated by the model to be evaluated.
        
        Returns:
            dict: A dictionary containing the evaluation result, the predicted answer, and the correct answer.
        """
        user_message = self.evaluate_answer_prompt.format(
            exmples=self.eval_examples if self.eval_examples else "",
            question=question, 
            correct_answer=correct_answer, 
            predicted_answer=predicted_answer
        )
        messages = [{'role': 'user', 'content': user_message}]
        agent_input = {
            'messages': messages,
            'json_schema': evaluate.EvaluateAnswerOutput,
            'index': 0
        }
        responses = self.llm_agent.generate(agent_input)['output']
        results = []
        reasoning = []
        for response in responses:
            response_object = response.get('output', None)
            if response_object is not None:
                if isinstance(response_object, evaluate.EvaluateAnswerOutput):
                    answer_status = response_object.result == 'matched' # True if the predicted answer is matched with the correct answer, False otherwise
                    results.append(answer_status)
                    reasoning.append(response_object.reasoning)
                else:
                    print(f"Warning: Response object is not of type EvaluateAnswerOutput: {response_object}")
        # Majority voting for the results
        if len(results) > 0:
            final_result = sum(results) / len(results) >= 0.5 # True if more than half of the responses are 'matched'
        else:
            # Print out to help debug the issue
            print(f"Warning: No valid responses received for evaluation")
            print(f"user_message: {user_message}")
            print(f"Responses: {responses}")
            final_result = False
        return {'result': final_result, 'predicted': predicted_answer, 'answer': correct_answer}
    
    def generate_direct_answer(self, question: str, context: str=None):
        """
        Generates a direct answer to a question using the LLM agent.
        
        Args:
            question (str): The question to be answered.
            context (str, optional): Additional context to inform the answer.
        
        Returns:
            dict: A dictionary containing the additional information, reasoning, and direct answer.
        """
        user_message = self.generate_direct_answer_prompt.format(
            examples=self.direct_answer_examples if self.direct_answer_examples else "",
            question=question, 
            context=context if context else ""
            )
        messages = [{'role': 'user', 'content': user_message}]
        agent_input = {
            'messages': messages,
            'json_schema': generate_direct_answer.DirectAnswerOutput,
            'index': 0
        }
        responses = self.llm_agent.generate(agent_input)['output']
        answers = []
        reasoning = []
        additional_information = []
        for response in responses:
            response_object = response.get('output', None)
            cot_reasoning = response.get('cot_reasoning', None)
            if response_object is not None:
                if isinstance(response_object, generate_direct_answer.DirectAnswerOutput):
                    answers.append(response_object.answer)
                    reasoning.append(response_object.reasoning)
                    additional_information.append(response_object.additional_information)
                else:
                    print(f"Warning: Response object is not of type DirectAnswerOutput: {response_object}")
        return {
            'answer': answers, # [str] 
            'reasoning': reasoning,
            'additional_information': additional_information
        }    

    def generate_follow_up_reasoning(self, question: str, context: str=None):
        """
        Generates a single next reasoning step that logically follows from the current reasoning to advance towards a complete answer to the question.
        Args:
            question (str): The question to be answered.
            context (str, optional): Additional context to inform the reasoning.
        Returns:
            dict: A dictionary containing the next reasoning step and its justification.
        """
        user_message = self.generate_one_next_step_prompt.format(
            examples=self.one_next_step_examples if self.one_next_step_examples else "",
            question=question, 
            context=context if context else ""
            )
        messages = [{'role': 'user', 'content': user_message}]
        agent_input = {
            'messages': messages,
            'json_schema': generate_one_next_step.OneNextStepOutput,
            'index': 0
        }
        responses = self.llm_agent.generate(agent_input)['output']
        next_steps = []
        justifications = []
        for response in responses:
            response_object = response.get('output', None)
            cot_reasoning = response.get('cot_reasoning', None)
            if response_object is not None:
                if isinstance(response_object, generate_one_next_step.OneNextStepOutput):
                    next_steps.append(response_object.next_step)
                    justifications.append(response_object.justification)
                else:
                    print(f"Warning: Response object is not of type OneNextStepOutput: {response_object}")
        return {
            'next_step': next_steps,  # [str]
            'justification': justifications
        }

    def generate_subquestion_and_answer(self, question: str, context: str=None):
        """
        Generates a subquestion and answer that logically follows from the main question, along with step-by-step reasoning.
        
        Args:
            question (str): The main question to be answered.
            context (str, optional): Additional context to inform the subquestion and answer.
        
        Returns:
            dict: A dictionary containing the generated subquestion, direct answer, and reasoning.
        """
        user_message = self.generate_subquestion_and_answer_prompt.format(
            examples=self.subquestion_and_answer_examples if self.subquestion_and_answer_examples else "",
            question=question, 
            context=context if context else "",
            )
        messages = [{'role': 'user', 'content': user_message}]
        agent_input = {
            'messages': messages,
            'json_schema': generate_subquestion_and_answer.SubquestionAndAnswerOutput,
            'index': 0
        }
        responses = self.llm_agent.generate(agent_input)['output']
        subquestions = []
        answers = []
        reasoning = []
        for response in responses:
            response_object = response.get('output', None)
            if response_object is not None:
                if isinstance(response_object, generate_subquestion_and_answer.SubquestionAndAnswerOutput):
                    subquestions.append(response_object.subquestion)
                    answers.append(response_object.answer)
                    reasoning.append(response_object.reasoning)
                else:
                    print(f"Warning: Response object is not of type SubquestionAndAnswerOutput: {response_object}")
        return {
            'subquestion': subquestions,  # [str]
            'answer': answers,  # [str]
            'reasoning': reasoning
        }

    def reanswer_subquestion(self, question: str, answer: str, context: str=None):
        """
        Reanswers a subquestion based on the main question and additional context, providing step-by-step reasoning.
        Args:
            question (str): The main question to be answered.
            answer (str): The answer to the subquestion that needs to be reanswered.
            context (str, optional): Additional context to inform the reanswering process.
        Returns:
            dict: A dictionary containing the reanswered subquestion and reasoning.
        """
        user_message = self.reanswer_subquestion_prompt.format(
            examples=self.reanswer_subquestion_examples if self.reanswer_subquestion_examples else "",
            question=question, 
            answer=answer, 
            context=context if context else ""
            )
        messages = [{'role': 'user', 'content': user_message}]
        agent_input = {
            'messages': messages,
            'json_schema': reanswer_subquestion.ReanswerOutput,
            'index': 0
        }
        responses = self.llm_agent.generate(agent_input)['output']
        reanswered_subquestions = []
        reasoning = []
        for response in responses:
            response_object = response.get('output', None)
            if response_object is not None:
                if isinstance(response_object, reanswer_subquestion.ReanswerOutput):
                    reanswered_subquestions.append(response_object.reanswer)
                    reasoning.append(response_object.reasoning)
                else:
                    print(f"Warning: Response object is not of type ReanswerOutput: {response_object}")
        return {
            'reanswered_subquestion': reanswered_subquestions,  # [str]
            'reasoning': reasoning
        }

    def rephase_question(self, question: str, context: str=None):
        """
        Rephrases a question to make it clearer, more specific, or more focused while retaining its original intent.
        
        Args:
            question (str): The question to be rephrased.
            context (str, optional): Additional context to inform the rephrasing process.
        
        Returns:
            dict: A dictionary containing the rephrased question and reasoning.
        """
        user_message = self.rephase_question_prompt.format(
            examples=self.rephase_question_examples if self.rephase_question_examples else "",
            question=question, 
            context=context if context else ""
            )
        messages = [{'role': 'user', 'content': user_message}]
        agent_input = {
            'messages': messages,
            'json_schema': rephase_question.RephraseQuestionOutput,
            'index': 0
        }
        responses = self.llm_agent.generate(agent_input)['output']
        rephrased_questions = []
        reasoning = []
        for response in responses:
            response_object = response.get('output', None)
            if response_object is not None:
                if isinstance(response_object, rephase_question.RephraseQuestionOutput):
                    rephrased_questions.append(response_object.rephrased_question)
                    reasoning.append(response_object.reasoning)
                else:
                    print(f"Warning: Response object is not of type RephraseQuestionOutput: {response_object}")
        return {
            'rephrased_question': rephrased_questions,  # [str]
            'reasoning': reasoning
        }
        
    def score_reasoning():
        pass

    def score_answer():
        pass

    def extract_information_from_retrieved_doc():
        pass


if __name__ == "__main__":
    # Example usage
    online_model_kwargs = {
        'model_name': 'qwen3-32b',
        'url': 'http://n0998.talapas.uoregon.edu:30000/v1',
        'api_key': 'None',
        'concurrency': 64,
    }
    generate_kwargs = {
        'temperature': 0.7,
        'n': 3, # should be odd number ás it is used for majority voting
        'top_p': 0.8,
        'max_tokens': 8192,
        'top_k': 20,
        'repetition_penalty': 1.5,
        'logprobs': 1,
        'tensor_parallel_size': 1,
    }

    genrator = Generator(online_model_kwargs=online_model_kwargs, generate_kwargs=generate_kwargs)

    question = "What are the most effective policies governments can implement to combat climate change?"
    context = "Climate change is a pressing global issue that requires immediate action. Governments play a crucial role in implementing policies to mitigate its effects. Effective policies include transitioning to renewable energy sources, implementing carbon pricing, promoting energy efficiency, and enhancing public transportation systems. Additionally, reforestation and conservation efforts can significantly reduce carbon emissions. International cooperation is also essential for addressing this global challenge."
    direct_answer = genrator.generate_direct_answer(question, context)
    breakpoint()
    next_step = genrator.generate_follow_up_reasoning(question)
    breakpoint()
    subquestion_and_answer = genrator.generate_subquestion_and_answer(question, context)
    breakpoint()
    subquestion_and_answer = genrator.generate_subquestion_and_answer(question)
    breakpoint()
    subquestion = "What are the most effective policies governments can implement to combat climate change?"
    subanswer = "Governments can implement a variety of effective policies to combat climate change, including transitioning to renewable energy sources, implementing carbon pricing, promoting energy efficiency, and enhancing public transportation systems."
    reanswer = genrator.reanswer_subquestion(subquestion, subanswer)
    breakpoint()
    rephrased_question = genrator.rephase_question(question, context)
    breakpoint()

